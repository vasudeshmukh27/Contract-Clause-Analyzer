# ğŸ“‹ Contract Clause Analyzer

> **AI-powered intelligent contract analysis system**  
> Automatically parse, classify, and extract key contractual clauses from PDFs using LLMs and vector embeddings.

![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-pgvector-336791?logo=postgresql&logoColor=white)
![Groq API](https://img.shields.io/badge/Groq-LLM-FF6B00)
![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?logo=streamlit&logoColor=white)

---

## ğŸ¯ What This Project Does

Contract Clause Analyzer is a **full-stack AI document intelligence platform** that helps procurement teams, legal departments, and contract managers quickly understand and compare vendor contracts.

**Key Workflow:**
1. ğŸ“¤ Upload PDF contracts
2. ğŸ” Automatic parsing & semantic chunking
3. ğŸ¤– LLM-powered clause classification
4. ğŸ“Š Interactive dashboard for insights
5. ğŸ“ˆ Analytics & comparison tools

---

## âœ¨ Core Features

### **8-Clause Classification System**
Automatically detect and extract:
- ğŸ”“ **Termination for Convenience** - Exit flexibility with notice periods
- ğŸ“Š **Data Sharing** - Privacy, confidentiality, and data handling terms
- ğŸ“¢ **Notice to Terminate** - Required notification periods
- âš–ï¸ **Governing Law** - Legal jurisdiction and venue
- ğŸ’° **Cap on Liability** - Financial exposure limits
- ğŸ”„ **Auto Renewal** - Automatic renewal terms and conditions
- ğŸ” **Audit Rights** - Right to inspect and verify
- ğŸ›¡ï¸ **Indemnification** - Indemnity and hold harmless clauses

### **Intelligent Processing Pipeline**
- âœ… PDF parsing with smart text extraction
- âœ… Semantic span generation (automatic chunking)
- âœ… Vector embeddings (384-dimensional)
- âœ… Hybrid classification (rule-based + LLM)
- âœ… Structured attribute extraction
- âœ… Confidence scoring

### **Interactive Web Dashboard**
- ğŸ“ Real-time PDF upload & processing
- ğŸ” Query & filter by clause type
- ğŸ“ˆ Termination flexibility scoring
- ğŸ“Š Contract analytics dashboard
- ğŸ’¾ Persistent database storage

---

## ğŸ“¦ Project Structure

```
contract-clause-analyzer/
â”‚
â”œâ”€â”€ ğŸ“„ Core Application Files
â”‚   â”œâ”€â”€ app.py                    # Streamlit web dashboard
â”‚   â”œâ”€â”€ ingest_one.py             # PDF â†’ Database pipeline
â”‚   â”œâ”€â”€ clause_detector.py        # LLM classification engine
â”‚   â”œâ”€â”€ schema.py                 # Database schema setup
â”‚   â””â”€â”€ schema.sql                # SQL table definitions
â”‚
â”œâ”€â”€ ğŸ› ï¸ Utility Scripts
â”‚   â”œâ”€â”€ count_clause_types.py     # Clause distribution analyzer
â”‚   â”œâ”€â”€ search_demo.py            # Vector search demonstration
â”‚   â”œâ”€â”€ migrate_vector_384.py     # Embedding migration utility
â”‚   â””â”€â”€ verify_db.py              # Database integrity checker
â”‚
â”œâ”€â”€ ğŸ“ Data Directories
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ contracts/            # Upload PDFs here â¬…ï¸
â”‚
â”œâ”€â”€ ğŸ”§ Configuration
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”œâ”€â”€ .env                      # Environment variables (create manually)
â”‚   â””â”€â”€ README.md                 # This file
â”‚
â””â”€â”€ ğŸ“ Documentation
    â””â”€â”€ I want to work on this genAI project...  # Project notes
```

---

## ğŸš€ Quick Start (5 Minutes)

### **Step 1: Clone & Setup Environment**

```bash
# Clone repository
git clone https://github.com/yourusername/contract-clause-analyzer.git
cd contract-clause-analyzer

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # macOS/Linux
```

### **Step 2: Install Dependencies**

```bash
pip install -r requirements.txt
```

### **Step 3: Configure Environment**

Create a `.env` file in project root:

```env
# PostgreSQL Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=contract_analyzer
DB_USER=postgres
DB_PASSWORD=your_postgres_password

# Groq API (Get free key: https://console.groq.com/keys)
GROQ_API_KEY=your_groq_api_key_here

# Optional: Sentence Transformer Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

### **Step 4: Setup PostgreSQL Database**

```bash
# Start PostgreSQL (Windows: Services, Mac: brew, Linux: systemctl)
psql -U postgres

# Create database
CREATE DATABASE contract_analyzer;
\c contract_analyzer;

# Run schema
\i schema.sql
```

Or use Python:
```bash
python schema.py
```

### **Step 5: Launch Dashboard**

```bash
streamlit run app.py
```

âœ… Open browser â†’ `http://localhost:8501`

---

## ğŸ“– Usage Guide

### **1. Upload & Analyze a Contract**

```
Sidebar â†’ "ğŸ“ Upload New Contract"
  â†“
Drag & drop PDF or click "Browse files"
  â†“
Click "ğŸ” Analyze Contract"
  â†“
Wait 2-5 minutes (depending on PDF size)
  â†“
Results appear in Query Results tab
```

### **2. Query Clauses**

```
Sidebar â†’ "Select Clause Type" dropdown
  â†“
Choose from 8 clause types
  â†“
View extracted clauses with:
  - Page number
  - Section heading
  - Text excerpt (200 characters)
  - Extracted attributes (JSON)
```

### **3. View Analytics**

```
Main â†’ "ğŸ“Š Analytics" tab
  â†“
See:
  - Total contracts processed
  - Total spans parsed
  - Classified vs. unclassified breakdown
  - Clause type distribution chart
```

### **4. Termination Flexibility Scoring**

When viewing "Termination for Convenience" clauses, they're ranked by **flexibility score**:

| Score Range | Meaning | Example |
|-----------|---------|---------|
| 0.9-1.0 | âœ… Very Flexible | 30-day notice, no fees, convenience termination |
| 0.5-0.7 | âš ï¸ Moderate | 60-day notice, 20% termination fee |
| 0.1-0.3 | âŒ Restrictive | 180-day notice, 50% penalty, auto-renewal |

---

## ğŸ”§ File Documentation

### **Core Scripts**

#### `app.py` (9 KB)
Streamlit web application - main user interface
- **Functions:** PDF upload, clause querying, analytics dashboard
- **Start:** `streamlit run app.py`

#### `ingest_one.py` (3 KB)
PDF ingestion pipeline
- **Functions:** Parse PDF â†’ extract spans â†’ generate embeddings â†’ store in DB
- **Start:** `python ingest_one.py --pdf <path> --vendor <name> --title <title>`

#### `clause_detector.py` (10 KB)
LLM-powered classification engine
- **Functions:** Classify unknown spans using Groq API
- **Start:** `python clause_detector.py`
- **Uses:** Hybrid approach (keyword detection + Groq LLM)

#### `schema.py` & `schema.sql`
Database initialization
- **Tables:** `documents`, `clause_spans`, `span_embeddings`
- **Functions:** Create tables, indexes, extensions
- **Start:** `python schema.py` or `psql -U postgres -f schema.sql`

### **Utility Scripts**

#### `count_clause_types.py` (1 KB)
Analyze distribution of classified clauses
- **Output:** Count of each clause type in database

#### `search_demo.py` (2 KB)
Demonstrate vector similarity search
- **Example:** Find similar contract clauses

#### `verify_db.py` (1 KB)
Check database integrity and row counts

#### `migrate_vector_384.py` (1 KB)
Utility for migrating embeddings to 384-dimensional vectors

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER UPLOADS PDF                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              INGEST_ONE.PY (Parsing Phase)                  â”‚
â”‚  â€¢ Extract text from PDF                                    â”‚
â”‚  â€¢ Split into semantic spans                                â”‚
â”‚  â€¢ Generate 384-dim embeddings                              â”‚
â”‚  â€¢ Store in PostgreSQL                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            CLAUSE_DETECTOR.PY (Classification)              â”‚
â”‚  â€¢ Fetch "Unknown" spans                                    â”‚
â”‚  â€¢ Rule-based keyword detection                             â”‚
â”‚  â€¢ Query Groq API for LLM classification                    â”‚
â”‚  â€¢ Extract structured attributes                            â”‚
â”‚  â€¢ Update clause_type & attributes                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              APP.PY (Dashboard & Query)                     â”‚
â”‚  â€¢ Display classified clauses by type                       â”‚
â”‚  â€¢ Calculate flexibility scores                             â”‚
â”‚  â€¢ Show analytics & charts                                  â”‚
â”‚  â€¢ Enable clause comparison                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Frontend** | Streamlit | Web UI & dashboard |
| **Backend** | Python 3.10+ | Core logic |
| **Database** | PostgreSQL + pgvector | Data storage & vector search |
| **LLM** | Groq API (Llama 3.3 70B) | Clause classification |
| **Embeddings** | SentenceTransformers | Semantic vectors (384-dim) |
| **PDF Parsing** | Unstructured | Text extraction |
| **ORM** | psycopg2 | Database connection |

---

## ğŸ“Š Clause Type Reference

| Clause | Keywords | Attributes Extracted | Example |
|--------|----------|-------------------|---------|
| **Termination for Convenience** | terminate, convenience, without cause, at will | `notice_days`, `termination_fee_required`, `termination_for_convenience` | "Either party may terminate for any reason with 30 days' notice" |
| **Data Sharing** | data, confidential, share, disclose, privacy | `data_categories`, `sharing_restrictions` | "Vendor shall not share client data with third parties without written consent" |
| **Notice to Terminate** | notice, days, written, advance | `notice_days`, `notice_type` | "Termination requires 90 days' written notice to either party" |
| **Governing Law** | governing law, jurisdiction, courts, state law | `governing_jurisdiction`, `venue` | "This Agreement shall be governed by California law" |
| **Cap on Liability** | liability, limit, exceed, damages, cap | `liability_cap_amount`, `liability_cap_type` | "Liability capped at fees paid in prior 12 months" |
| **Auto Renewal** | renew, automatic, successive, renewal term | `renewal_period`, `auto_renewal_enabled` | "Automatically renews for successive one-year terms" |
| **Audit Rights** | audit, inspect, examine, records, books | `audit_frequency`, `audit_scope` | "Client may audit Vendor's records upon 30 days' notice" |
| **Indemnification** | indemnify, hold harmless, defend, indemnified | `indemnifying_party`, `indemnified_party` | "Vendor shall indemnify and hold Client harmless from third-party claims" |

---

## ğŸ› Troubleshooting

### Error: `ModuleNotFoundError: No module named 'psycopg2'`
```bash
pip install psycopg2-binary
```

### Error: `GROQ_API_KEY not found`
- âœ… Create `.env` file in project root
- âœ… Get key from https://console.groq.com/keys
- âœ… Set `GROQ_API_KEY=your_key`

### Error: `Rate limit exceeded (429)`
- Free tier: 100K tokens/day
- âœ… Wait for reset or upgrade at https://console.groq.com/settings/billing

### Error: `PostgreSQL connection refused`
```bash
# Verify PostgreSQL is running
# Windows: Services â†’ PostgreSQL (running?)
# Mac: brew services list | grep postgres
# Linux: sudo systemctl status postgresql
```

### Error: `No clause types found`
- Threshold may be too high
- âœ… Reduce `min_conf=0.1` in `clause_detector.py`
- âœ… Verify contract contains target clause language

---

## ğŸ“ˆ Performance Metrics

| Metric | Value |
|--------|-------|
| **Parsing Speed** | ~5-10 seconds per contract |
| **Classification Speed** | ~2-3 minutes per 100 spans (depends on Groq API) |
| **Embedding Dimension** | 384-dimensional vectors |
| **Database Size** | ~1-2GB per 1000 contracts |
| **Free Tier Limit** | 100K tokens/day |

---

## ğŸš€ Deployment

### **Local Development**
```bash
streamlit run app.py
```

### **Production (Ubuntu 20.04)**

```bash
# Install
sudo apt-get update && sudo apt-get install python3.10 postgresql

# Setup
cd /opt && sudo git clone <repo>
cd contract-analyzer && pip install -r requirements.txt

# Run with systemd
sudo systemctl start contract-analyzer
```

---

## ğŸ’¡ Example Use Cases

### **1. Vendor Contract Review**
- Upload 5 vendor MSAs
- Compare termination flexibility scores
- Export results for procurement team
- Negotiate terms before signing

### **2. Legal Compliance Check**
- Audit all active contracts
- Identify data sharing risks
- Check liability caps
- Ensure governing law compliance

### **3. Contract Standardization**
- Analyze competitor contracts
- Extract best practices
- Create template terms
- Build procurement playbook

---

## ğŸ“ How It Works (Technical Deep Dive)

### **Phase 1: Ingestion** (ingest_one.py)
1. Parse PDF â†’ Extract text elements
2. Create semantic spans (typically paragraph-sized)
3. Generate 384-dim embeddings via SentenceTransformer
4. Insert into PostgreSQL with pgvector

### **Phase 2: Classification** (clause_detector.py)
1. Query all "Unknown" spans
2. Rule-based keyword detection
3. Call Groq API for LLM classification
4. Extract JSON attributes (notice days, fees, etc.)
5. Update database with clause_type

### **Phase 3: Visualization** (app.py)
1. Query PostgreSQL by clause_type
2. Calculate termination flexibility scores
3. Render in Streamlit
4. Display analytics charts

---

## ğŸ“ Environment Variables

```env
# Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=contract_analyzer
DB_USER=postgres
DB_PASSWORD=YourPassword

# API
GROQ_API_KEY=your_groq_key

# Models
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

---

## ğŸ”’ Security Notes

- âš ï¸ Never commit `.env` file to Git
- âš ï¸ Use strong PostgreSQL passwords
- âš ï¸ Rotate Groq API keys regularly
- âš ï¸ Store PDFs in secure location
- âš ï¸ Audit who has database access

---

## ğŸ“ Support & Contributing

### **Issues?**
- Check `#troubleshooting` section
- Open GitHub issue with error message
- Include `.env` excerpt (without sensitive data)

### **Want to Contribute?**
```bash
git checkout -b feature/amazing-feature
git commit -m "Add amazing feature"
git push origin feature/amazing-feature
```

---

## ğŸ‰ What's Next?

- [ ] Multi-contract comparison matrix
- [ ] Risk scoring system
- [ ] Custom clause templates
- [ ] REST API endpoints
- [ ] Batch processing UI
- [ ] Excel/PDF export
- [ ] Contract versioning
- [ ] Team collaboration

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ‘ Acknowledgments

- **Groq** - Free LLM API access
- **PostgreSQL & pgvector** - Semantic search
- **Streamlit** - Rapid UI development
- **Unstructured** - PDF parsing
- **SentenceTransformers** - Embeddings

---

**Built with â¤ï¸ for intelligent contract analysis**

*Last Updated: October 29, 2025*